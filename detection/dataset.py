import os
import torch
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as T
from PIL import Image
from torchvision.transforms.functional import to_pil_image
from torchvision import transforms

class PotholeDataset(Dataset):
    def __init__(self, image_dir, label_dir):
        self.image_dir = image_dir
        self.label_dir = label_dir
        self.to_tensor = transforms.ToTensor()
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (—Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ .jpg)
        self.image_files = [f for f in os.listdir(image_dir) if f.endswith(".jpg")]

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        img_name = self.image_files[idx]
        img_path = os.path.join(self.image_dir, img_name)
        image = Image.open(img_path).convert('RGB').resize((576,576))
        orig_width, orig_height = image.size  # (W, H) –≤ PIL
        image = self.to_tensor(image)
        

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –º–µ—Ç–∫–∏ (bounding boxes)
        label_path = os.path.join(self.label_dir, img_name.replace(".jpg", ".txt"))
        boxes = []
        labels = []

        with open(label_path, "r") as f:
            for line in f.readlines():
                parts = line.strip().split()
                class_id = int(parts[0])  # –ü–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç ‚Äî ID –∫–ª–∞—Å—Å–∞
                x_center, y_center, width, height = map(float, parts[1:])  # YOLO —Ñ–æ—Ä–º–∞—Ç

                #x_min, y_min, x_max, y_max = map(float, parts[1:])
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º YOLO-—Ñ–æ—Ä–º–∞—Ç –≤ [x_min, y_min, x_max, y_max]
                x_min = (x_center - width / 2) * orig_width
                y_min = (y_center - height / 2) * orig_height
                x_max = (x_center + width / 2) * orig_width
                y_max = (y_center + height / 2) * orig_height

                boxes.append([x_min, y_min, x_max, y_max])
                #boxes.append([x_center, y_center, width, height])
                labels.append(class_id)

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä—ã
        boxes = torch.tensor(boxes, dtype=torch.float32)
        labels = torch.tensor(labels, dtype=torch.int64)

        # –°–æ–∑–¥–∞—ë–º target
        target = {"boxes": boxes, "labels": labels}
        return image, target

def get_dataloaders(root_dir, batch_size=8):
    # –ü—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º
    train_img_dir = os.path.join(root_dir, "train", "images")
    train_lbl_dir = os.path.join(root_dir, "train", "labels")
    valid_img_dir = os.path.join(root_dir, "valid", "images")
    valid_lbl_dir = os.path.join(root_dir, "valid", "labels")

    # –°–æ–∑–¥–∞—ë–º –¥–∞—Ç–∞—Å–µ—Ç—ã
    train_dataset = PotholeDataset(train_img_dir, train_lbl_dir)
    valid_dataset = PotholeDataset(valid_img_dir, valid_lbl_dir)

    # –°–æ–∑–¥–∞—ë–º DataLoader
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,  collate_fn=lambda x: tuple(zip(*x)))
    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))

    return train_loader, valid_loader


























######################
import os
import torch
import numpy as np
from PIL import Image, ImageDraw, ImageFont


def draw_bounding_boxes(images, targets, save_dir="tmp"):
    """
    –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ—Ç bounding boxes –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –∏—Å–ø–æ–ª—å–∑—É—è PIL.
    
    :param images: –°–ø–∏—Å–æ–∫ —Ç–µ–Ω–∑–æ—Ä–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (batch)
    :param targets: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏ (bounding boxes –∏ labels)
    :param save_dir: –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    """
    os.makedirs(save_dir, exist_ok=True)  # ‚úÖ –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç

    for i, (image, target) in enumerate(zip(images, targets)):
        # ‚úÖ –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º PyTorch Tensor –≤ NumPy (–µ—Å–ª–∏ —ç—Ç–æ –Ω–µ NumPy)
        if isinstance(image, torch.Tensor):
            image = image.cpu().detach().numpy()

        # ‚úÖ –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ `[C, H, W]`, –º–µ–Ω—è–µ–º –æ—Å–∏ –Ω–∞ `[H, W, C]`
        if image.shape[0] == 3:  # –ö–∞–Ω–∞–ª—ã –≤ –ø–µ—Ä–≤–æ–º –∏–∑–º–µ—Ä–µ–Ω–∏–∏ (C, H, W)
            image = np.transpose(image, (1, 2, 0))

        # ‚úÖ –ü—Ä–∏–≤–æ–¥–∏–º –∑–Ω–∞—á–µ–Ω–∏—è –≤ –¥–∏–∞–ø–∞–∑–æ–Ω [0, 255] –∏ –¥–µ–ª–∞–µ–º `uint8`
        image = (image * 255).astype(np.uint8)

        # ‚úÖ –°–æ–∑–¥–∞—ë–º –æ–±—ä–µ–∫—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ PIL
        pil_image = Image.fromarray(image)

        # ‚úÖ –°–æ–∑–¥–∞—ë–º –æ–±—ä–µ–∫—Ç –¥–ª—è —Ä–∏—Å–æ–≤–∞–Ω–∏—è
        draw = ImageDraw.Draw(pil_image)

        # ‚úÖ –ü–æ–ª—É—á–∞–µ–º bounding boxes –∏ –º–µ—Ç–∫–∏
        boxes = target["boxes"].cpu().numpy()
        labels = target["labels"].cpu().numpy()

        # ‚úÖ –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ–º bounding boxes
        for box, label in zip(boxes, labels):
            x_min, y_min, x_max, y_max = box
            #x_center, y_center, width, height = box
            #x_min = (x_center - width / 2) * image.shape[1]
            #y_min = (y_center - height / 2) * image.shape[0]
            #x_max = (x_center + width / 2) * image.shape[1]
            #y_max = (y_center + height / 2) * image.shape[0]
            print([x_min, y_min, x_max, y_max])
            draw.rectangle([x_min, y_min, x_max, y_max], outline="green", width=5)
            draw.text((x_min, y_min - 10), f"Class {label}", fill="green")

        # ‚úÖ –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        save_path = os.path.join(save_dir, f"annotated_{i}.jpg")
        pil_image.save(save_path)
        print(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {save_path}")


# üìå –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
train_loader, valid_loader = get_dataloaders(root_dir="D:\\study\\pits_detection\\detection\\data")

# –ü–æ–ª—É—á–∞–µ–º batch
tmp = next(iter(train_loader))
images, targets = tmp[0], tmp[1]

# –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ–º –±–æ–∫—Å—ã –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
draw_bounding_boxes(images, targets)


# –ü–æ–ª—É—á–∞–µ–º batch
tmp = next(iter(train_loader))
images, targets = tmp[0], tmp[1]

img = images[0]
from PIL import Image
from torchvision.transforms.functional import to_pil_image
pil_img = to_pil_image(img)
pil_img.save(r'detection\tmp\tmp.jpg')



# –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ–º –±–æ–∫—Å—ã –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
draw_bounding_boxes(images, targets)

